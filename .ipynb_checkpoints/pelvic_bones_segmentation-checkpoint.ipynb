{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation et configuration de l’expérience\n",
    "### Téléchargement des données \n",
    "Lien 1 (données): [https://zenodo.org/record/4588403#.YEyLq_0zaCo](https://zenodo.org/record/4588403#.YEyLq_0zaCo)\n",
    "- Télécharger: \n",
    "  - CTPelvic1K_dataset6_data.tar.gz\n",
    "  - CTPelvic1K_dataset6_Anonymized_mask.tar.gz\n",
    "  - CTPelvic1K_Models.tar.gz\n",
    "\n",
    "\n",
    "Lien 2 (projet de base): [https://github.com/ICT-MIRACLE-lab/CTPelvic1K](https://github.com/ICT-MIRACLE-lab/CTPelvic1K)\n",
    "### Décompression des données et mise en place d'une base de données brutes\n",
    "Le but est de reproduire l'expérience déjà faite. Pour choisir la facilité (sans modifier les chemins dans le fichier nnunet/paths.py), il faut créer un dossier nommé **all_data** dans le répertoire Home (dans mon cas '/home/lotfi'. Ensuite, creer un autre dossier nommé **nnUNet** dans **all_data** et un autre **rawdata** dans **nnUNet**, ce qui donne un chemin absolu **/home/lotfi/all_data/nnUNet/rawdata** (dans mon cas). Ou bien, exécuter le script suivant:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/home/lotfi/all_data2/nnUNet/rawdata' created\n"
     ]
    }
   ],
   "source": [
    "# Creation du dossier pour les données brutes\n",
    "import os\n",
    "home_dir = os.environ['HOME']\n",
    "dir_name = os.path.join(home_dir,'all_data/nnUNet/rawdata')\n",
    "os.makedirs(dir_name)\n",
    "print(\"Directory '% s' created\" % dir_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Décompresser les differents fichiers téléchargés\n",
    "- Mettre tous les fichiers ***.nii.gz** (data et labels, c-à-d, tous les fichiers de CTPelvic1K_dataset6_data et CTPelvic1K_dataset6_Anonymized_mask ) dans le **même** dossier **rawdata** qui vient d'etre créer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation d'un virtual environment pour le projet et installation des packages requis \n",
    "Après avoir télécharger le projet de base sur github [(ce lien)](https://github.com/ICT-MIRACLE-lab/CTPelvic1K) et l'evoir décompresser, copier le dans l'endroit de votre choix. Dans mon cas, '*Documents*'. Son chemain absolu est donc '/home/lotfi/Documents/CTPelvic1K-main'.\n",
    "\n",
    "Dans le terminal (sous Gnu Linux, dans mon cas / [Suivre ce lien pour plus de détails et pour les autres systemes d'exploitation](https://docs.python.org/3/library/venv.html)):\n",
    ">* python3 -m venv /path/to/new/virtual/environment\n",
    "\n",
    ">* cd /path/to/new/virtual/environment\n",
    "\n",
    ">*  source bin/activate\n",
    "\n",
    ">*  pip install -r path/to/requirements.txt\n",
    "\n",
    "**Exemple**\n",
    "\n",
    "Créer un envirenment virtuel **pytorch3DBonesSeg** le dossier '*PythonVirutalEnvirenments*'\n",
    ">* python3 -m venv PythonVirutalEnvirenments/pytorch3DBonesSeg\n",
    "\n",
    ">* cd PythonVirutalEnvirenments/pytorch3DBonesSeg\n",
    "\n",
    ">* source bin/activate\n",
    "\n",
    ">*  pip install -r /home/lotfi/Documents/CTPelvic1K-main/requirements.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarque\n",
    "- Pour utiliser la suite de ce jupyter notebook,  Copier ce Notebook dans le dossier du projet de base->nnunet.\n",
    "- S'assurer d'utiliser l'envirenment virtuel déjà crée [Suivre sur lien, par exemple, pour plus de détails](https://janakiev.com/blog/jupyter-virtual-envs/). Dans mon cas, j'ai copié la configuration du noyau python existant (dossier appelé '***puthon3***') se trouvant dans '*/home/lotfi/anaconda3/share/jupyter/kernels*' dans un autre dossier que j'ai renommé '***pytorch3DBonesSeg_venv***' et j'ai édité le fichier '***kenel.json***' qui se trouve à l'interieur  comme suit:\n",
    ">{\n",
    ">>\"argv\": [\n",
    "\n",
    ">>  \"/home/lotfi/PythonVirutalEnvirenments/pytorch3DBonesSeg/bin/python\",\n",
    " \n",
    ">> \"-m\",\n",
    "\n",
    ">>  \"ipykernel_launcher\",\n",
    " \n",
    ">>  \"-f\",\n",
    "\n",
    ">>  \"{connection_file}\"\n",
    " \n",
    ">> ],\n",
    " \n",
    ">> \"display_name\": \"pytorch3DBonesSeg_venv\",\n",
    " \n",
    ">> \"language\": \"python\"\n",
    " \n",
    ">}\n",
    "\n",
    "Les deux dossiers '***python3****' et '***pytorch3DBonesSeg_venv***' se trouvent alors cote à cote dans le meme dossier '**/home/lotfi/anaconda3/share/jupyter/kernels**'.\n",
    "Lors du lancement de jupyter-notebook, il faut choisir ***pytorch3DBonesSeg_venv*** comme noyau pour pouvoir utiliser l'envirenment virtuel dédié au projet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution des scripts des du projet\n",
    "## Conversion de la serie dicom (ou des séries dicom) en un seul fichier (un fichier par série)\n",
    "Pour pouvoir utiliser les models entrainé sur de nouvelles donnée, il faudra que celles-ci soit au méme format que les données d'entrainment NIFTI au lieu de DCM.\n",
    "pour convertir un dossier contenant une ou plusieurs séries de fichier dicom en des fichiers nifti, utiliser la fonction suivante:\n",
    "\n",
    ">* dicom2nifti.convert_directory(source_folder, destination_folder)\n",
    "\n",
    "Toutfois, il faut avoir installer au préalable une librairie dcm_converter, (sinon, on aura une erreur GDCMCONV_NOT_FOUND).\n",
    "Dans mon cas, sous Debian (gnu linux), j'ai installé la libraire libgdcm-tools. pour ce faire, dans le terminal:\n",
    ">* sudo apt install libgdcm-tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversion de la série proposé par Dr. BRAHIM comme test, changer le chemain pour l'adapter à votre cas!!\n",
    "# Ici, j'ai mis tous les fichiers dicom dans /home/lotfi/all_data/data/dicom_test\n",
    "import os\n",
    "import dicom2nifti\n",
    "home_dir = os.environ['HOME']\n",
    "dicom2nifti.convert_directory('/home/lotfi/all_data/data/dicom_test', '/home/lotfi/all_data/data/nifti_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de faire l'entrainement des nnunet, changer le chemain de test_dir par le chemain vers le dossier de test.\n",
    "\n",
    "Dans mon cas : *test_dir= '/home/lotfi/all_data/data/nifti_test'*\n",
    "\n",
    "## Mise en place de la base de données à partir des données brutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ici, il y aura plusieurs dossiers qui seront crées et qui seront utilisés pour l'entrainement\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from pelvic_bones_segmentation.paths import my_output_identifier\n",
    "home_dir = os.environ['HOME']\n",
    "train_dir = os.path.join(home_dir,'all_data/nnUNet/rawdata')\n",
    "output_dir = os.path.join(home_dir, 'all_data/nnUNet/nnUNet_raw/Task11_CTPelvic1K')\n",
    "command_1 = f'python dataset_conversion/JstPelvisSegmentation_5label.py --train_dir {train_dir} --output_dir {output_dir}'\n",
    "os.system(command_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planification de l'experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please cite the following paper when using CTPelvic1K dataset:\n",
      "\n",
      "Pengbo, Liu, et al. \"Deep Learning to Segment Pelvic Bones: Large-scale CT Datasets and Baseline Models.\" arXiv preprint arXiv: (2021).\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/ICT-MIRACLE-lab/CTPelvic1K\n",
      "Please cite the following paper when using CTPelvic1K dataset:\n",
      "\n",
      "Pengbo, Liu, et al. \"Deep Learning to Segment Pelvic Bones: Large-scale CT Datasets and Baseline Models.\" arXiv preprint arXiv: (2021).\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/ICT-MIRACLE-lab/CTPelvic1K\n",
      "here ***** 4\n",
      "here **** 1\n",
      "here **** 2\n",
      "train_dataset6_CLINIC_0001\n",
      "train_dataset6_CLINIC_0008\n",
      "train_dataset6_CLINIC_0002\n",
      "train_dataset6_CLINIC_0003\n",
      "train_dataset6_CLINIC_0009train_dataset6_CLINIC_0004\n",
      "\n",
      "train_dataset6_CLINIC_0015train_dataset6_CLINIC_0005train_dataset6_CLINIC_0010\n",
      "\n",
      "\n",
      "train_dataset6_CLINIC_0006train_dataset6_CLINIC_0011\n",
      "\n",
      "train_dataset6_CLINIC_0007\n",
      "train_dataset6_CLINIC_0012\n",
      "train_dataset6_CLINIC_0013\n",
      "train_dataset6_CLINIC_0016\n",
      "train_dataset6_CLINIC_0017\n",
      "train_dataset6_CLINIC_0014\n",
      "train_dataset6_CLINIC_0018\n",
      "train_dataset6_CLINIC_0019\n",
      "train_dataset6_CLINIC_0020\n",
      "train_dataset6_CLINIC_0021\n",
      "train_dataset6_CLINIC_0029\n",
      "train_dataset6_CLINIC_0036\n",
      "train_dataset6_CLINIC_0030train_dataset6_CLINIC_0037\n",
      "\n",
      "train_dataset6_CLINIC_0038train_dataset6_CLINIC_0031\n",
      "\n",
      "train_dataset6_CLINIC_0032train_dataset6_CLINIC_0039\n",
      "\n",
      "train_dataset6_CLINIC_0033\n",
      "train_dataset6_CLINIC_0040\n",
      "train_dataset6_CLINIC_0041\n",
      "train_dataset6_CLINIC_0034\n",
      "train_dataset6_CLINIC_0042\n",
      "train_dataset6_CLINIC_0035\n",
      "train_dataset6_CLINIC_0043\n",
      "train_dataset6_CLINIC_0044\n",
      "train_dataset6_CLINIC_0045\n",
      "train_dataset6_CLINIC_0050\n",
      "train_dataset6_CLINIC_0046\n",
      "train_dataset6_CLINIC_0047\n",
      "train_dataset6_CLINIC_0051\n",
      "train_dataset6_CLINIC_0048\n",
      "train_dataset6_CLINIC_0052\n",
      "train_dataset6_CLINIC_0049\n",
      "train_dataset6_CLINIC_0053\n",
      "train_dataset6_CLINIC_0054\n",
      "train_dataset6_CLINIC_0055\n",
      "train_dataset6_CLINIC_0056\n",
      "train_dataset6_CLINIC_0057\n",
      "train_dataset6_CLINIC_0058\n",
      "train_dataset6_CLINIC_0059\n",
      "train_dataset6_CLINIC_0060\n",
      "train_dataset6_CLINIC_0061\n",
      "train_dataset6_CLINIC_0062\n",
      "train_dataset6_CLINIC_0063\n",
      "train_dataset6_CLINIC_0064\n",
      "train_dataset6_CLINIC_0065\n",
      "train_dataset6_CLINIC_0066\n",
      "train_dataset6_CLINIC_0071\n",
      "train_dataset6_CLINIC_0067\n",
      "train_dataset6_CLINIC_0072\n",
      "train_dataset6_CLINIC_0068\n",
      "train_dataset6_CLINIC_0073\n",
      "train_dataset6_CLINIC_0074\n",
      "train_dataset6_CLINIC_0069\n",
      "train_dataset6_CLINIC_0075\n",
      "train_dataset6_CLINIC_0076\n",
      "train_dataset6_CLINIC_0070\n",
      "train_dataset6_CLINIC_0077\n",
      "train_dataset6_CLINIC_0078\n",
      "train_dataset6_CLINIC_0079\n",
      "train_dataset6_CLINIC_0085train_dataset6_CLINIC_0080\n",
      "\n",
      "train_dataset6_CLINIC_0081\n",
      "train_dataset6_CLINIC_0082\n",
      "train_dataset6_CLINIC_0086\n",
      "train_dataset6_CLINIC_0083\n",
      "train_dataset6_CLINIC_0084\n",
      "train_dataset6_CLINIC_0087\n",
      "train_dataset6_CLINIC_0088\n",
      "train_dataset6_CLINIC_0089train_dataset6_CLINIC_0092\n",
      "\n",
      "train_dataset6_CLINIC_0093\n",
      "train_dataset6_CLINIC_0090\n",
      "train_dataset6_CLINIC_0094\n",
      "train_dataset6_CLINIC_0095\n",
      "train_dataset6_CLINIC_0091\n",
      "train_dataset6_CLINIC_0096\n",
      "train_dataset6_CLINIC_0097\n",
      "train_dataset6_CLINIC_0098\n",
      "train_dataset6_CLINIC_0099\n",
      "train_dataset6_CLINIC_0100\n",
      "train_dataset6_CLINIC_0101\n",
      "train_dataset6_CLINIC_0102\n",
      "train_dataset6_CLINIC_0103\n",
      "train_dataset6_CLINIC_0022\n",
      "train_dataset6_CLINIC_0023\n",
      "train_dataset6_CLINIC_0024\n",
      "train_dataset6_CLINIC_0025\n",
      "train_dataset6_CLINIC_0026\n",
      "train_dataset6_CLINIC_0027\n",
      "train_dataset6_CLINIC_0028\n",
      "here **** 3\n",
      "here ***** 5\n",
      "here ***** 6\n",
      "/home/lotfi/all_data/nnUNet/nnUNet_processed\n",
      "Task11_CTPelvic1K\n",
      "{0: {'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 96, 160, 128]), 'median_patient_size_in_voxels': array([153, 224, 224]), 'current_spacing': array([1.82707924, 1.91617857, 1.91617857]), 'original_spacing': array([0.79998779, 0.83899999, 0.83899999]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}, 1: {'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 96, 160, 128]), 'median_patient_size_in_voxels': array([350, 512, 512]), 'current_spacing': array([0.79998779, 0.83899999, 0.83899999]), 'original_spacing': array([0.79998779, 0.83899999, 0.83899999]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}}\n",
      "Initializing to run preprocessing\n",
      "npz folder: /home/lotfi/all_data/nnUNet/nnUNet_raw_cropped/Task11_CTPelvic1K\n",
      "output_folder: /home/lotfi/all_data/nnUNet/nnUNet_processed/Task11_CTPelvic1K\n"
     ]
    }
   ],
   "source": [
    "# j'ai réduit le nombre de process à 4, avant c'etait 12, la RAM est rapidement saturée dans le cas de 12 process\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from pelvic_bones_segmentation.paths import my_output_identifier\n",
    "home_dir = os.environ['HOME']\n",
    "train_dir = os.path.join(home_dir,'all_data/nnUNet/rawdata/Task11_CTPelvic1K')\n",
    "output_dir = os.path.join(home_dir, 'all_data/nnUNet/nnUNet_raw/Task11_CTPelvic1K')\n",
    "command_2 = 'python experiment_planning/plan_and_preprocess_task.py -t Task11_CTPelvic1K -pl 4 -pf 4'\n",
    "os.system(command_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prétraitement et préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "home_dir = os.environ['HOME']\n",
    "processed_path = os.path.join(home_dir, 'all_data/nnunet_data/Lotfi_task')\n",
    "check_save_path = os.path.join(home_dir, 'all_data/nnunet_data/Lotfi_task/Lotfi_task_check')\n",
    "command_3 = f'python preprocessing/lumbosacral_joint_sampling.py --processed_path {processed_path} --check_save_path {check_save_path}'\n",
    "os.system(command_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement des differnts modeles de unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "home_dir = os.environ['HOME']\n",
    "TASK = 'Task11_CTPelvic1K'\n",
    "FOLD = 0\n",
    "GPU = 0\n",
    "command = f'python run/run_training.py 2d nnUNetTrainer {TASK} {FOLD} --gpu {GPU}' # TASK fold gpu_idx\n",
    "# command = f'python run/run_training.py 3d_fullres nnUNetTrainer {TASK} {FOLD} --gpu {GPU}'\n",
    "# command = f'python run/run_training.py 3d_lowres nnUNetTrainer {TASK} {FOLD} --gpu {GPU}'\n",
    "# command = f'python run/run_training.py 3d_cascade_fullres nnUNetTrainerCascadeFullRes {TASK} {FOLD} --gpu {GPU}\n",
    "os.system(command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "home_dir = os.environ['HOME']\n",
    "TASK = 'Task11_CTPelvic1K'\n",
    "FOLD = 0\n",
    "GPU = 0\n",
    "# command = f'python run/run_training.py 2d nnUNetTrainer {TASK} {FOLD} --gpu {GPU}' # TASK fold gpu_idx\n",
    "command = f'python run/run_training.py 3d_fullres nnUNetTrainer {TASK} {FOLD} --gpu {GPU}'\n",
    "# command = f'python run/run_training.py 3d_lowres nnUNetTrainer {TASK} {FOLD} --gpu {GPU}'\n",
    "# command = f'python run/run_training.py 3d_cascade_fullres nnUNetTrainerCascadeFullRes {TASK} {FOLD} --gpu {GPU}\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "home_dir = os.environ['HOME']\n",
    "TASK = 'Task11_CTPelvic1K'\n",
    "FOLD = 0\n",
    "GPU = 0\n",
    "# command = f'python run/run_training.py 2d nnUNetTrainer {TASK} {FOLD} --gpu {GPU}' # TASK fold gpu_idx\n",
    "# command = f'python run/run_training.py 3d_fullres nnUNetTrainer {TASK} {FOLD} --gpu {GPU}'\n",
    "command = f'python run/run_training.py 3d_lowres nnUNetTrainer {TASK} {FOLD} --gpu {GPU}'\n",
    "# command = f'python run/run_training.py 3d_cascade_fullres nnUNetTrainerCascadeFullRes {TASK} {FOLD} --gpu {GPU}\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "home_dir = os.environ['HOME']\n",
    "TASK = 'Task11_CTPelvic1K'\n",
    "FOLD = 0\n",
    "GPU = 0\n",
    "# command = f'python run/run_training.py 2d nnUNetTrainer {TASK} {FOLD} --gpu {GPU}' # TASK fold gpu_idx\n",
    "# command = f'python run/run_training.py 3d_fullres nnUNetTrainer {TASK} {FOLD} --gpu {GPU}'\n",
    "# command = f'python run/run_training.py 3d_lowres nnUNetTrainer {TASK} {FOLD} --gpu {GPU}'\n",
    "command = f'python run/run_training.py 3d_cascade_fullres nnUNetTrainerCascadeFullRes {TASK} {FOLD} --gpu {GPU}''\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation des modeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "home_dir = os.environ['HOME']\n",
    "TASK = 'Task11_CTPelvic1K'\n",
    "FOLD = 0\n",
    "GPU = 0\n",
    "command_8  = f'python run/run_training.py 2d nnUNetTrainer {TASK} {FOLD} --gpu {GPU} --validation_only --valbest'\n",
    "os.system(command_8)\n",
    "\n",
    "command_9  = f'python run/run_training.py 3d_fullres nnUNetTrainer {TASK} {FOLD} --gpu {GPU} --validation_only --valbest'\n",
    "os.system(command_9)\n",
    "\n",
    "command_10 = f'python run/run_training.py 3d_lowres nnUNetTrainer {TASK} {FOLD} --gpu {GPU} --validation_only --valbest'\n",
    "os.system(command_10)\n",
    "\n",
    "command_11 = f'python run/run_training.py 3d_cascade_fullres nnUNetTrainerCascadeFullRes {TASK} {FOLD} --gpu {GPU} --validation_only --valbest'\n",
    "os.system(command_11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test sur les nouvelles données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "home_dir = os.environ['HOME']\n",
    "TASK = 'Task11_CTPelvic1K'\n",
    "FOLD = 0\n",
    "GPU = 0\n",
    "\n",
    "test_data_path = os.path.join(home_dir, '/home/lotfi/all_data/data/nifti_test')\n",
    "\n",
    "command_12 = f'python inference/predict_simple.py ' \\\n",
    "             f'-i {test_data_path} ' \\\n",
    "             f'-o {test_data_path}/{TASK}__{my_output_identifier}__fold{FOLD}_2d_pred ' \\\n",
    "             f'-t {TASK} ' \\\n",
    "             f'-tr nnUNetTrainer ' \\\n",
    "             f'-m 2d ' \\\n",
    "             f'-f {FOLD} ' \\\n",
    "             f'--gpu {GPU}'\n",
    "os.system(command_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "home_dir = os.environ['HOME']\n",
    "TASK = 'Task11_CTPelvic1K'\n",
    "FOLD = 0\n",
    "GPU = 0\n",
    "command_13 = f'python inference/predict_simple.py ' \\\n",
    "              f'-i {test_data_path} ' \\\n",
    "              f'-o {test_data_path}/{TASK}__{my_output_identifier}__fold{FOLD}_3dfullres_pred ' \\\n",
    "              f'-t {TASK} ' \\\n",
    "              f'-tr nnUNetTrainer ' \\\n",
    "              f'-m 3d_fullres ' \\\n",
    "              f'-f {FOLD} ' \\\n",
    "              f'--gpu {GPU}'\n",
    "\n",
    "os.system(command_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "home_dir = os.environ['HOME']\n",
    "TASK = 'Task11_CTPelvic1K'\n",
    "FOLD = 0\n",
    "GPU = 0\n",
    "command_14 = f'python inference/predict_simple.py ' \\\n",
    "              f'-i {test_data_path} ' \\\n",
    "              f'-o {test_data_path}/{TASK}__{my_output_identifier}__fold{FOLD}_3dlowres_pred ' \\\n",
    "              f'-t {TASK} ' \\\n",
    "              f'-tr nnUNetTrainer ' \\\n",
    "              f'-m 3d_lowres ' \\\n",
    "              f'-f {FOLD} ' \\\n",
    "              f'--gpu {GPU} ' \\\n",
    "              f'--overwrite_existing 0'\n",
    "os.system(command_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "home_dir = os.environ['HOME']\n",
    "TASK = 'Task11_CTPelvic1K'\n",
    "FOLD = 0\n",
    "GPU = 0\n",
    "my_task_lowres = TASK\n",
    "my_output_identifier_lowres = 'CTPelvic1K' #your low_res experiment\\'s \"my_output_identifier\" in path\n",
    "command_15 = f'python inference/predict_simple.py ' \\\n",
    "              f'-i {test_data_path} ' \\\n",
    "              f'-o {test_data_path}/{TASK}__{my_output_identifier_lowres}__{my_output_identifier}__fold{FOLD}_3dcascadefullres_pred ' \\\n",
    "              f'-t {TASK} ' \\\n",
    "              f'-tr nnUNetTrainerCascadeFullRes ' \\\n",
    "              f'-m 3d_cascade_fullres ' \\\n",
    "              f'-f {FOLD} ' \\\n",
    "              f'-l {test_data_path}/{my_task_lowres}__{my_output_identifier_lowres}__fold{FOLD}_3dlowres_pred ' \\\n",
    "              f'--gpu {GPU} ' \\\n",
    "              f'--overwrite_existing 0'\n",
    "\n",
    "os.system(command_15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
